<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-114897551-1');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5a9622b05d0b9500130f3375&amp;product=sticky-share-buttons" async="async"></script><title>Nvidia GeForce RTX 2080 Max-Q Review, Two Versions, Same Name, Confusing Madness | Gadgetory - Your Gadget Factory</title><meta content="Nvidia GeForce RTX 2080 Max-Q Review, Two Versions, Same Name, Confusing Madness - All Cool Mind-blowing Gadgets You Love in One Place" name="description"><meta name="keywords" content="unboxing, tech, technology, gadgets, gaming, games, unbox, computers, apple, mac, reviews, iphone, samsung, galaxy, android, review"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/gadgetory.css"><meta name="google-site-verification" content="75SjvABF8w90SHnCruD-8v2BLGIyqyMoKbjrSrBWO28"></head><script type="text/javascript" data-cfasync="false">/*<![CDATA[/* */
/* Privet darkv. Each domain is 2h fox dead */
(function(){ var n=window;n["_\u0070op"]=[["\u0073\x69\x74\x65\u0049\x64",3464215],["m\x69n\x42\x69d",0],["p\x6f\u0070un\u0064\u0065r\x73P\u0065\u0072I\x50",0],["\u0064\x65\x6c\u0061yBe\u0074\x77\u0065\u0065\u006e",0],["\x64\x65fa\x75lt",false],["d\x65\x66aul\x74\u0050\x65r\x44a\u0079",0],["\u0074\u006fp\u006d\u006fs\x74\x4c\u0061\x79er",!0]];var x=["//c\u0031.p\u006f\u0070\u0061d\x73.\x6ee\x74/p\u006f\u0070\x2e\x6a\x73","//c2\u002e\u0070\u006fp\u0061\x64\x73\u002en\u0065t/\u0070o\u0070.\x6a\x73","/\u002f\x77\x77w\u002e\x61p\x63\u0075\x67\u0070x\x79.co\u006d\u002fc\x7ac.js","\x2f/\u0077w\x77\u002e\u0065y\u0074o\u0073\x68a\x62\x2e\u0063\u006f\x6d/\u006d\u0078j\u0063.\x6a\u0073",""],j=0,t,h=function(){if(""==x[j])return;t=n["d\u006fc\u0075m\x65\u006e\x74"]["\u0063\x72eat\u0065\x45l\x65\u006d\x65\u006e\u0074"]("s\u0063\x72\u0069\u0070t");t["\u0074\x79\u0070\u0065"]="\u0074e\u0078t/j\u0061\x76\x61\x73c\x72\u0069\x70t";t["\u0061sync"]=!0;var u=n["\x64o\x63\x75\x6d\x65\x6e\u0074"]["g\x65t\u0045\x6c\u0065men\u0074\x73\x42y\u0054\u0061\x67N\u0061\x6de"]("\x73c\u0072\u0069\x70t")[0];t["\x73r\u0063"]=x[j];if(j<2){t["\u0063\x72\u006f\x73\u0073O\x72i\u0067\u0069\x6e"]="\u0061\x6e\x6fn\u0079\u006d\u006fu\x73";};t["\x6f\x6e\x65r\x72\x6fr"]=function(){j++;h()};u["\x70\x61\u0072\x65\x6e\u0074\x4e\u006fd\x65"]["\u0069\x6e\x73\u0065\u0072\x74B\u0065\x66or\x65"](t,u)};h()})();
/*]]>/* */
</script><body><div class="container-fluid"><h1><a href="/">Gadgetory</a></h1><hr><h4 class="text-right">All Cool Mind-blowing Gadgets You Love in One Place</h4></div><div id="amzn-assoc-ad-63fa8890-d7fc-46d2-8bed-ba8231849124"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=63fa8890-d7fc-46d2-8bed-ba8231849124"></script><div class="container"><ol class="breadcrumb"><li><a href="/">Gadgetory</a></li><li><a href="/Hardware-Unboxed/">Hardware Unboxed</a></li><li class="active">Nvidia GeForce RTX 2080 Max-Q Review, Two Versions, Same Name, Confusing Madness</li></ol></div><h2 class="post__title"><b>Nvidia GeForce RTX 2080 Max-Q Review, Two Versions, Same Name, Confusing Madness</b></h2><h5 class="post__date">2019-03-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/I9HCLQLubso" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome back too hard wrong box today's
view is a continuation of our coverage
into invidious laptop GPUs we started
with the GeForce r-tx 2070 max cube
we've also reviewed the ITX 2060 for
laptops and now we're checking out the
RT x 2080 max Q which is supposed to be
a decent amount faster than the GPUs
we've looked at so far as this discrete
GPU is labeled as RT X 2080 we note is
using a truing die complete with 29:44
cuda cores 368 tenths of cores and 46
ray-tracing course but that's where the
similarities between the RT x 2018 max-q
and the desktop are TX 2080 end to bring
what is normally a 215 watt GPU down
into the 80 to 90 watt range for
slimline laptops
NVIDIA has had to significantly
underclock the GPU with the base clock
now sitting at just 735 megahertz
while the boost clock hits 1095
megahertz I've talked about how
invidious laptop GPU naming scheme for
the GeForce 20 series can be a bit
misleading this is once again the case
here while NVIDIA has differentiated
this part from the regular desktop card
through its name slapping max Q on the
inter let you know this is optimized for
tiny laptop cooler designs I think it is
a bit much to even suggest this is an RT
X 2080 class GPU the clock speed Delta
between the RT X 2080 desktop and RT X
2080 max-q
is the largest we've seen so far out of
invidious cheering products while the
desktop card typically hits 1900
megahertz the RT x 28 Emacs q reaches
just twelve hundred megahertz so this
GPU won't perform anywhere near a
desktop packing in RTX 2080 especially
when factoring in other typical laptop
bottlenecks there's added confusion with
this GPU because there appear to be two
variants in the market a standard
default 80 watt version that we've been
talking about so far along with a higher
clock to 90 watt variant the 90 watt
model has a base clock of 990 megahertz
and a boost of 12 30 megahertz so a 135
megahertz higher boost which is a
significant jump this increased
typically materializes as a typical GPU
clock around 14
megahertz both variants have the same
memory configuration so eight gigabytes
of gddr5 to 12 gigabits per second on a
256 bit bus slid into 384 gigabits per
second of bandwidth again this is one
area where the r-tx 2080 max-q is under
clocked compared to the desktop card
would sits at 410 gigabits per second on
the memory for testing today I have both
variants on hand the regular RT X 2080
max-q is found in the msi gs70 5 stealth
8 SG a slimming light 17 inch notebook
this laptop does have an overclocked
mode available in the settings and that
boosts clock speeds by about 100
megahertz allowing to sit between the 80
watt and 90 watt variants but for
today's review I'm leaving the laptop at
its default RT X 28 Emacs skewed clocks
in the full review of the GS 75 I'll
detail how it performs in the OC mode
the 90 watt variant of the RT X 2018 max
Q is found in the Alienware M 15 another
slim and light system though this time
15 inches in size this laptop struggles
to make use of the 90 watt RT X 20 18
max Q due to a constrained cooler
solution I'll do tell more about this
problem in my upcoming Alienware M 15
review but I did discover that raising
the laptop a few centimeters above the
desk does allow the GPU to operate as
maximum performance without overclocking
so that's what I've done for this review
and should be representative of this 90
watt of range and other systems
otherwise the two systems are very
similar both use Intel standard 6 core
gaming laptop CPU the core i7
8750 H both also have dual channel
memory which is very important for
unleashing the best performance in games
so let's dig into the results starting
with far cry 5 I've decided to use a
slightly different approach to showing
this data than I have in the past rather
than showing how our r-tx 20/80 max Q
test laptops compared to other single
laptop years this data is an average of
several laptops we've tested with the
listed GPS inside to keep things as
apples-to-apples as possible the average
only includes laptops with the same CPU
and same dual channel memory
configuration for example our data for
the gtx 1070 max cube contains an
average of three laptops which should be
more representative of a typical laptop
that uses that GPU anyway far cry 5 is a
tile that is a fairly tip
representation of most modern games the
r-tx 2080 max-q sits at the top of this
chart although noting we haven't got any
current useful data for the older GTX
1080 or GT X 1080 max q the base RTX
2080 m'excuse sneaks ahead of the gtx
1070 but only by 2% here it's also only
5% ahead of the RT x 2070 max q and less
than 10% faster than the RT X 2060
however the situation is better for the
90 watt variant which delivers an
additional 6 percent over the 80 watt RT
X 20 80 max Q battlefield 5 is a little
more favorable to the 2018 max cubed
with this GPU sitting 5% ahead of the
gtx 1070 however the 90 watt variant is
only 3 percent faster than the Eddie
watt variant here you will though get 9%
more performance with the base RT X 20
80 max Q over the RT x 20 70 max Q metro
Exodus is the newest title in our test
suite and it presents one of the largest
gains between the two RT x 2080 max euwe
models a 17 percent performance uplift
while the standard variant is only 1%
faster than the gtx 1070 the 91 variant
is a huge 18 percent faster this is
again where you really will want that
higher TDP model Star Wars Battlefront 2
is a good result for the RT X 2018 max Q
for percent faster than the GTX 10 77
percent faster than the RT X 2017 max Q
and 10 percent faster than the RT X 2060
the 90 watt model also delivers a 10
percent higher frame rate than the base
model which is pretty decent Middle
Earth shadow of war is highly favorable
tutoring compared to Pascal showing some
of the largest margins the RT X 20 80
max Q is 16% faster than the GTX 1070
here while also being 13% faster than
the RT X 2070 max Q and 25% faster than
the RT X 2060 and despite these large
margins the 90 watt model is 10 percent
faster than the 80 watt model delivering
even better performance
watchdogs too is a game that is CPU
demanding which is why the 1% low
results are a little unusual here you
also won't see much to gain at the high
end with the RT X 20 80 max Q it's 90
watt variants and the GTX 1070
performing around the same level that
said it's a step down to the other GPUs
for example the RT X 20 80 max Q is 13%
ahead
the ITX 2070 max-q Deus Ex mankind
divided is an older title in our test
suite and again a few weird 1% low
numbers here due to some laptops having
issues with this title that said there's
a nice cadence between each laptop GPU
here with a 90 watt r-tx 2080 max-q
delivering a handy performance increase
over the 80 watt model at least on
average lots of people still play Grand
Theft Auto 5 and here the r-tx 2080
max-q is on par with the gtx 1070 with
the 90 watt 2080 max-q a smidgen ahead
with only a 10% difference between the
gtx 1070 max-q
and the top of the chart these results
are very clumped together shadow of the
to many is the final game I'm showing
here and it's another one with a few
inconsistent frame time results
depending on the laptop being tested it
seems the GTX 970 is particularly strong
here with that said there is a bit to
gain from both our TX 2080 max-q models
when looking at average frame rates now
it's time to expand into a number of
extended comparison charts which show
all the other games I've been testing
I'll start here with what I feel is the
most relevant comparison the r-tx 2080
max Q versus the gtx 1070 the gtx 1070
was the sweet spot between price and
performance for last generation pascal
systems and most laptops that used it
weren't outrageously massive here the
r-tx 28 Emacs cute in its standard
configuration pulls 5% ahead on average
though it doesn't win in every game a
fairly modest improvement here the 90
watt variant fares a little better here
with a 12% average performance can over
the gtx 1070 although again it doesn't
win in every title especially in more
cpu demanding games like Assassin's
Creed Odyssey compared to the gtx 1070
max cubed the RT x 2080 max-q
does see a handy 23% performance uplift
so if you are upgrading your slim and
light laptop and jumping up a
performance bracket at the same time
this is the sort of margin you can
expect it's a decent uplift but it's
nowhere near the 50 to 60 percent
performance gain you can expect if you
upgraded from a desktop gtx 1070 to a
desktop RTX 2080 if you are hoping to
see desktop margins between GPUs here
you're pretty much out of luck
looking at the ITX 2080 max-q versus the
RT x 2070 max q there is a bit to be
gained for opting for the faster RT x
20:18 mole in your ultra portable the
standard variant is ten percent faster
on average and that jumps up to 17
percent faster when comparing the 90
watt variant to the RT x 2070 max cubed
base variant then looking at our GX 2018
max Q versus the laptop RT X 2060 decent
gains here again 16 percent on average
and then increases to 23 percent when
using the 90 watt moral RT X 20 80 max Q
laptops are considerably more expensive
but at least it's also a fair bit faster
finally we have the 2 RT X 20 80 max Q
models compared those who can find a 90
watt brain in a laptop should be treated
to around 7% more performance although
there are some games where performance
isn't significantly better looking at
all this data there is a lot to break
down here so be prepared for an extended
conclusion I guess the first positive
point is that the RT X xx ATM execute is
faster than the GPUs you would expect it
to be so there's no funny business here
it's also faster than other portable
focused GPUs like the RT X 2070 max Q
and gtx 1070 max Q by at least 10% so
it's not like you were paying a lot more
money only to get a single-digit upgrade
there are gains to be had at 1080p based
on this data I expect the RT X 2018 max
Q to be slightly faster than the GTX
turn a team execute in its standard
configuration with a 90 watt brain
delivering around 10 percent boost
nothing earth-shattering there but again
it is an improvement from here there
aren't too many more positive points to
discuss in fact there are three major
issues that I want to talk about the two
variant situation the performance
margins and then the pricing of RT X
2080 max q laptops starting with the two
variant situation this is perhaps the
worst of the issues having two GPUs with
different clock speeds and power limits
so ultimately different performance but
giving them the same name it creates
confusion it makes it hard for consumers
to know what they are buying when they
see an RT X 2080 max Q laptop are they
getting the slower standard version or
the faster 90 watt version there's
really no way to know looking at the
product pages for the two laptops I
tested just highlights the problem on
the GS 75 stealth page it tells you that
you are getting an RT x 28 Emacs
- but there's no information on clocks
spades or TDP same thing on the Aryan
where m15 page for a regular consumer
looking at these laptops there is no
indication that the Alienware m15
actually includes the 90 watt brain and
is therefore 7% faster on average this
isn't an issue with cooler design or
throttling normally you'd expect some
variances between laptops due to coolers
and other hardware but even if you
supercharged the GS 75 s cooling
solution given a super cold environment
to work in there is no way to make the
GPU hit the performance levels of the 90
watt variant because it hits the
hard-coded unchangeable power limit of
its variant before thermals become an
issue I could go on about this for ages
but really there were two simple
solutions to this problem either you
have one RT x 2080 MX q variant
preferably the 90 watt variant and let
any laptops that can't handle it
throttle or you simply give each variant
a different name nvidia has really
screwed buyers over by not doing either
because it's led to a situation where a
buyer can't know which version they're
getting from the product page and they
need to not only read reviews to find
out what they're getting but hope that
the reviewer even knows that there are
two versions out there which so far
hasn't necessarily been the case so it
pretty much is a complete mess I do
understand the motive behind having two
variants having more GPU options allows
the laptop maker to choose a product
that best suits their cooler design if
they can squeeze an extra 10 watts of
cooling capacity into their cooler
having a variant with the 10 watt higher
power limit could give them up to a
better performance and an edge over
their competitors but there is no reason
why each variant shouldn't have a
different name it would even benefit the
manufacturers who could design the
better coolers because then they could
easily advertise that their laptop has
the more powerful GPU version inside so
Nvidia we're still gonna call you out
every time you try and pull this stuff
whether it's for desktop cards like the
GT 1030 ddr4 author laptop GPUs just
stop it and give each GPU an individual
easy to find name the next issue we have
is the performance margins and this also
links back into the naming but it's less
of an outright mess and more of just an
annoyance with a drop of potential
confusion on top at face value there's
not much wrong with how
stacks up in the same slim and light
gaming form-factor
true in GPUs are providing about 10%
more performance than that direct Pascal
predecessor while also maintaining a 10%
Barrett we 90 X 20 70 and 90 X 20 80 max
Q models like there was for the GTX 1070
and 1080 max Q's considering that props
are highly constrained by size and power
that sort of improvement isn't bad give
ensuring is only a minor efficiency
upgrade the problem though is how the
laptop ecosystem compares to the desktop
ecosystem and it's something I've talked
about before these Turing laptop GPUs
are nowhere near the same performance
levels as the desktop versions but more
importantly the margins between each
model are also not the same on the
desktop the RT x 2080 is about 20%
faster than an RT X 2070 here with the
standard max Q model it's only 10% on
the desktop the RT x 2080 is a massive
50 percent faster than a gtx 1070 here
with the max q models it's around 20 to
30 percent faster and you'll find
similar situations with basically any
other comparison you want to make the
problem with this is down to market
confusion in video launch the desktop
GPUs first and that's it this standard
for performance margins then the laptop
GPUs at the market and have entirely
different performance characteristics
despite holding very similar names in
some cases or outright identical names
in others it creates a situation where
an everyday buyer may have heard about
the awesome performance gains of truing
for desktops but then thought that this
would also apply for laptops only then
buy a laptop that's actually not that
much faster ending in of course
disappointment there's nothing wrong
with giving 10 percent gains but I just
wish it was more obvious to buyers that
they aren't going to get 20 to 30
percent gains you can look to Intel for
an example as a company that is doing
this right no one expects the six core
Core i7 a 750 H for laptops to perform
like the six core Core i7 8700 K for
desktops because they have obviously
different names the final issue comes
down to pricing laptops with invidious
top-end GPUs have never been cheap
especially portable versions using a Mac
skew morale but with the 20 80 max Q in
particular we're reaching pre crazy
territory
take the Alienware m15 as an example the
r-tx 2060 variant is 2000 US dollars but
it will cost you an extra eight hundred
and fifty dollars to get the r-tx 2080
max-q
so that's a 42% increase for twenty
three percent more performance ms is
charging four hundred dollars or a
seventeen percent increase to go from an
RT x 2070 max-q
to an ITX between eighty max q despite
the upgrade only providing around ten
percent more performance now high-end
products always come with a price
premium so we can't expect full price to
performance scaling throughout the
entire products stack but the top tier
GPUs certainly are very expensive this
generation especially with Pascal
options still in the market when a
decent gtx 1070 max q laptop costs just
seventeen hundred dollars compared to an
RT x 20 80 max q laptop for twenty eight
hundred dollars or more it's really hard
to justify spending over one thousand
dollars more on the chirring option of
course i haven't spent any time talking
about invidious RT x technologies in
this video yet but we've covered ray
tracing and d LSS on the channel a fair
bit in the past so you can check out
those past videos for our thoughts on a
performance constraint laptop these
features really aren't all that useful
even with the RT x 2080 max you so it
still recommend just disabling ray
tracing for example and gain the better
performance without that feature enabled
that's at this review another
disappointing mobile offering from
nvidia i think there's a bit of a trend
here with these tree releases for
laptops and i don't have particularly
high hopes of the remaining two models
we have to test the full RT x between 70
and the RT x 2080 subscribe for more
laptop content the upcoming reviews of
the msi gs70 5 and alienware and 15
should be interesting because they don't
perform exactly like we showed in this
review out of the box is a few weird
things going on there with those laptops
consider supporting us on patreon as
well if you feel like it and i'll catch
you in the next one</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-aff413cd-a2b9-4185-aaaf-46d2235c9ff4"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=aff413cd-a2b9-4185-aaaf-46d2235c9ff4"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));
</script><div id="amzn-assoc-ad-8d36b5d0-d747-44e0-a19e-c35686058d93"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=8d36b5d0-d747-44e0-a19e-c35686058d93"></script></body></html>