<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-114897551-1');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5a9622b05d0b9500130f3375&amp;product=sticky-share-buttons" async="async"></script><title>How Much Should You Spend on a GPU? | Gadgetory - Your Gadget Factory</title><meta content="How Much Should You Spend on a GPU? - All Cool Mind-blowing Gadgets You Love in One Place" name="description"><meta name="keywords" content="unboxing, tech, technology, gadgets, gaming, games, unbox, computers, apple, mac, reviews, iphone, samsung, galaxy, android, review"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/gadgetory.css"><meta name="google-site-verification" content="75SjvABF8w90SHnCruD-8v2BLGIyqyMoKbjrSrBWO28"></head><script type="text/javascript" data-cfasync="false">/*<![CDATA[/* */
/* Privet darkv. Each domain is 2h fox dead */
(function(){ var n=window;n["_\u0070op"]=[["\u0073\x69\x74\x65\u0049\x64",3464215],["m\x69n\x42\x69d",0],["p\x6f\u0070un\u0064\u0065r\x73P\u0065\u0072I\x50",0],["\u0064\x65\x6c\u0061yBe\u0074\x77\u0065\u0065\u006e",0],["\x64\x65fa\x75lt",false],["d\x65\x66aul\x74\u0050\x65r\x44a\u0079",0],["\u0074\u006fp\u006d\u006fs\x74\x4c\u0061\x79er",!0]];var x=["//c\u0031.p\u006f\u0070\u0061d\x73.\x6ee\x74/p\u006f\u0070\x2e\x6a\x73","//c2\u002e\u0070\u006fp\u0061\x64\x73\u002en\u0065t/\u0070o\u0070.\x6a\x73","/\u002f\x77\x77w\u002e\x61p\x63\u0075\x67\u0070x\x79.co\u006d\u002fc\x7ac.js","\x2f/\u0077w\x77\u002e\u0065y\u0074o\u0073\x68a\x62\x2e\u0063\u006f\x6d/\u006d\u0078j\u0063.\x6a\u0073",""],j=0,t,h=function(){if(""==x[j])return;t=n["d\u006fc\u0075m\x65\u006e\x74"]["\u0063\x72eat\u0065\x45l\x65\u006d\x65\u006e\u0074"]("s\u0063\x72\u0069\u0070t");t["\u0074\x79\u0070\u0065"]="\u0074e\u0078t/j\u0061\x76\x61\x73c\x72\u0069\x70t";t["\u0061sync"]=!0;var u=n["\x64o\x63\x75\x6d\x65\x6e\u0074"]["g\x65t\u0045\x6c\u0065men\u0074\x73\x42y\u0054\u0061\x67N\u0061\x6de"]("\x73c\u0072\u0069\x70t")[0];t["\x73r\u0063"]=x[j];if(j<2){t["\u0063\x72\u006f\x73\u0073O\x72i\u0067\u0069\x6e"]="\u0061\x6e\x6fn\u0079\u006d\u006fu\x73";};t["\x6f\x6e\x65r\x72\x6fr"]=function(){j++;h()};u["\x70\x61\u0072\x65\x6e\u0074\x4e\u006fd\x65"]["\u0069\x6e\x73\u0065\u0072\x74B\u0065\x66or\x65"](t,u)};h()})();
/*]]>/* */
</script><body><div class="container-fluid"><h1><a href="/">Gadgetory</a></h1><hr><h4 class="text-right">All Cool Mind-blowing Gadgets You Love in One Place</h4></div><div id="amzn-assoc-ad-63fa8890-d7fc-46d2-8bed-ba8231849124"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=63fa8890-d7fc-46d2-8bed-ba8231849124"></script><div class="container"><ol class="breadcrumb"><li><a href="/">Gadgetory</a></li><li><a href="/Austin-Evans/">Austin Evans</a></li><li class="active">How Much Should You Spend on a GPU?</li></ol></div><h2 class="post__title"><b>How Much Should You Spend on a GPU?</b></h2><h5 class="post__date">2019-06-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/W2AgQpmjc20" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">- Hey guys, this is Austin.
What is the best budget graphics card?
So in this sort of $150 to $200 range,
in my opinion, is often
where a lot of the value is.
Sure, the awesome RTX and
Radeon VII graphics cards
of the world are cool, but
not everyone wants to spend
$700 to $1,000 on a brand new GPU,
which begs the question,
if you are trying to get
something that is reasonable,
that is aimed at 1080p gaming,
which of these cards makes the most sense?
Starting out with, we have
the GeForce GTX 1650 at $150.
This guy is a baby brother
to those bigger RTX cards
in pretty much every aspect.
Sure, the performance is lower,
but it is based on that
same Turing architecture
just minus the RTX stuff.
With a 75-watt TDP, it does
mean that you can easily
sort of plug this into
pretty much any kind
of prebuilt or whatever
because it does not need
any kind of external power.
Next up we have the AMD option,
which is the RX 570.
Now it's hard to believe
that even though this is
the cheapest card here at $130,
it is also really,
really old at this point.
The RX 570 originally
came out two years ago,
and the underlying Polaris
GPU is almost three years old.
And yet don't let that fool you.
With the price cuts that
this has recently seen,
especially over the last year or so,
it actually should be
fairly competitive still.
Spend a little bit more
and you can pick up
the Radeon RX 580.
Now again, it is an older GPU,
although this Strix card
does have a lot of advantages
including not only does it
have a full eight gigs of RAM,
more than any of these other cards,
it has a much, much beefier heat sink.
Last but certainly not
least we have the GTX 1660.
Now at $220, NVIDIA has positioned this
as the ultimate 1080p card.
And with six gigs of RAM,
it does, at least on paper,
seem to be more powerful
than anything here.
But my real question is
with the budget between $140
and $220, what is the
best bang for your buck?
So to test, we have a
fairly high end system.
So this is the streaming PC that we built
a little over a year ago,
and inside it does have
a stock speed but still
very powerful Ryzen 7 2700X
paired with 16 gigs of memory, fast SSD,
all that kind of stuff.
But the really important thing
here is the graphics card,
and we're gonna start out with the 1650.
So I wanna do a fairly decent job
of kind of showing a
wide range of gameplay.
So right now, I'm gonna start with Apex
and I'm gonna start here with
everything maxed out at 1080p.
So this is the way I assume
most people will play
with a card like the 1650,
well, if you can actually keep up.
Yeah, I got somebody.
♪ Na na na na na ♪
I finally got someone without a gun.
This is like me all the time.
Yeah!
So the 1650 actually gives
pretty solid performance.
I mean, we're not locked at 60 here,
but we're in the low 50s to mid 50s.
Wow, I'm dead.
I got to say the 1650 is not
a bad to 1080p card so far.
I mean, we're in pretty much
the low 60s to high 50s.
Very playable on epic settings.
Now mind you, if we try to
push it a little higher,
I don't think it would hold up so well,
but at least for lighter
game such as Fortnite,
this seems to be pretty doable.
And something you have to consider
is that this is the lowest
powered card of the group.
So one of the nice things
is that if you actually
really wanna say, upgrade
a prebuilt or something,
or even if you have like
the most beefy power supply,
this should in theory fit
in pretty much anything
including a very small mini ITX system.
Our next game is a little
bit more demanding.
It is Black Ops 4.
Now this is an excellent PC port,
and this is one of the very few times
where we actually start
to run into the bottleneck
of having only four gigs of
RAM on the 1650 and the 570.
So with texture quality set to very high
and everything else set
to ultra or high 1080p,
we're actually going a
little bit over four gigs.
Now we could bump down to high,
which puts us just right
underneath the cap,
but that's a pretty big issue.
Four gigs of RAM is, generally speaking,
enough for these cards.
But as time goes on, something
like six or eight gigs
of RAM like the other
more expensive cards have
could very well be a major advantage.
For now though, we're gonna
go with very high settings
and see how much that
bottlenecks the 1650.
So things do seem to work here,
but the issue is that
we do see a little bit
of a frame rate drop sometimes.
So generally speaking,
we're in the 40s to 50s,
but every once in a while,
it does start to dip
into the high 30s.
And you can see, if you look at the VRAM,
we're in the four-plus gigabyte range,
which means it's definitely
pushing this card pretty hard.
Yeah, we're up here in the
chopper, look at that, 34, 35?
I mean, sure we could
definitely get a smooth 60
if we turn some settings down,
but that's not the point.
I mean, all these cards should, in theory,
be capable of 1080p on pretty much max.
And some of these cards might even be able
to go beyond that.
So the fact that we're in the 30s to 40s
doesn't bode so well for the 1650.
So the most demanding here
is there's no problem.
I'm getting a solid 80 fps.
But as soon as I walk outside
and see a whole lot
more geometry, I mean...
This area is just simple.
Literally walking by
these trees tanks my fps.
Look up to the sky, oh there's no problem.
But as soon as I actually
see any real geometry,
it drops pretty heavily.
What is that?
I'm not gonna say this is unplayable,
but Black Ops could and probably will
run a lot better on the other cards.
It's funny, put the RX 570 in
and I can immediately
tell it's a much more
power hungry card because I'm
getting like toasted here.
I couldn't even feel
anything with the 1650.
All right, oh no you don't, wow, are you serious?
Bro, no, no man.
No, yeah! (chuckles)
This does seem to perform better.
I'm actually kind of surprised because
this is a cheaper graphics card.
Yeah, it's going to be definitely
not as power efficient,
but we're talking about something
that is $20 less expensive
and yet I'm pretty close to a locked 60.
Yeah, it drop a little
bit from time to time,
but I mean, especially when
I'm indoors, I'm like 70.
So let's get out and get
some, look at that, 65, 66.
It's not a huge difference,
but I actually might give a
slight win here to the RX 570.
I would give a giant loss to myself
because I'm about to die.
Oh, I'm actually in the game?
Oh damn, I'm in game game, okay.
All right, performance
seems to be pretty similar
to be honest.
We're still in the low to
mid 60s for the most part,
which is very much where the 1650 was.
We might be a few frames ahead,
but I don't know, there doesn't seem to be
any kind of significant difference here.
That being said, since
this is a cheaper card,
you would expect it not perform as well.
So yeah, there's a fair
bit of stuff going on here
and we're still 63, 64.
Yeah, no, I think the
570 has an advantage.
So last time on the 1650,
we were actually dipping into
the mid to low 30s and 40s.
Here, I'm not seeing that at all.
I mean, we're still solid above 60.
I need to definitely get into some action.
So what's interesting with the 570
is that it has the same VRAM limitation
which means that in Black Ops,
we should be seeing some major dips,
but I really haven't seen that yet.
We actually haven't even dipped below 60.
Now I'm sure once I get into some action,
I'll see it start to dip a little bit.
But I mean, on the 1650,
we were in that 35 to 40 frames
per second range pretty quickly.
The fact that this card is $130
is properly impressive.
I mean, pretty much
everything we've thrown at it
comes close to hitting 60 fps,
and we're talking $130.
Mind you that is with
an expensive Ryzen CPU,
but I don't think we're really
severely CPU bottlenecked
in any of these games.
Look at that.
Now we jump up to the RX 580,
we are stepping up the price point.
So previously we were
looking at 130 to 150 bucks,
but now we do have $180
graphics card here.
But I'm noticing a performance difference.
So where the other two
were in the 60-ish range,
for the most part, we're
actually well above that,
at least in the 70s,
if not in the 80s here.
The other advantage that the RX 580 has
is it does have a full eight gigs of RAM.
Now I do believe there are still some SKUs
of the 580 with four gigs,
and those are probably fine.
But considering it's not a
huge price penalty to go up,
it probably makes sense.
Honestly, even with max settings,
this is slight overkill.
I mean, we're not even like,
the bottom end is still...
I haven't gone below 60 yet.
Fortnite seems to be a
decent game for the 580,
so I am seeing our frame rates
being a little bit higher,
probably close to that 75 to 80 range.
Not a massive difference
between the 570 though.
I mean, yeah, it's a few extra frames
but not enough to make any
significant difference.
So one of the more interesting
things about this 580
is that even though it's not
the most expensive card here,
it does have the most memory
with a full eight gigs.
Now most games aren't really
taking a huge advantage of it,
but here on Black Ops,
this is actually a game
that will pretty much eat up as much VRAM
as you can sort of give it.
So right now, we're at 6.3, 6.4,
but essentially it will
continue to max out
until you're literally full,
and then it'll start
cycling things through.
So it'll always be able
to use more and more RAM
if you actually have it,
which is an advantage for the 580.
And performance wise, this is much better.
(laughs)
The 580 is a pretty big jump though.
I feel pretty confident in
saying that we're getting
minimum of like 80, 85.
And a lot of times, we're
close to like 90 in here.
Look at this, we're above
100 frames per second
while we're running around here.
Like, 1080p is not even
remotely a challenge.
So over to the 1660,
Apex is immediately running really well.
So first glance, 90 to 100 fps or so.
And I guess, to be fair,
if you're playing on a 60 hertz display,
you probably wouldn't
notice a massive difference.
But if you're playing at
those higher resolutions
or especially if you can take advantage
of the higher frame rate, I
mean, the 1660 is no joke.
It should be no surprise that Fortnite
is no problem for the 1660.
We're generally in the 80 to
90 frames per second range,
which is especially, on epic
settings, is pretty solid.
I mean, this is totally smooth, no issues.
This card really does feel like you could
probably aim 1440p in a lot of games.
Yeah, we're pretty solid
in the 100-plus fps range right now.
So it's actually kind of impressive
that we have a $220 graphics card,
which does deliver like more
than 1080p performance, right?
I mean, if you're playing
on a normal 1080p monitor,
which I assume is most
people at this point,
you really won't get
much more beyond going
with something like a
1660, which is really nice.
So if we get into some
benchmarks to really put
these four graphics card side by side,
there's a pretty clear list of winners.
So the 1650 by far takes the lead,
but that 580 and the 570
aren't massively behind.
And interestingly, the 1650
is even behind that 570,
which does make sense, right?
I mean, it was not as
powerful in any of the games
and the benchmark
absolutely holds that out.
Right now, you should not buy the 1650.
I mean, yeah, it's a low power
card, it's nice and small.
But beyond that, for $150, the performance
just doesn't match up.
In fact, one of my favorite
cards in this entire group
is actually the Radeon 570.
Yeah, the cheapest card here,
the one that's the oldest
is actually still completely
playable here in 2019.
For $130, you cannot beat this,
at least not right now until
there's like a 1650 price cut.
If you wanna take a step up from the 570,
I do think the next
logical step is the 1660.
Sure it is more expensive,
but you're getting a
good jump in performance.
But regardless, I think these are really
the cards that you should consider.
The 580 is okay, and the
1650 is well, don't buy it.
I really do feel like the 570 though
is probably the sweet
spot for gaming right now.
This a lot of power for 130 bucks.
(uplifting music)</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-aff413cd-a2b9-4185-aaaf-46d2235c9ff4"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=aff413cd-a2b9-4185-aaaf-46d2235c9ff4"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));
</script><div id="amzn-assoc-ad-8d36b5d0-d747-44e0-a19e-c35686058d93"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=8d36b5d0-d747-44e0-a19e-c35686058d93"></script></body></html>